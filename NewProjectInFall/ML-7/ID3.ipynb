{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ID3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLqttNoTn2TX/+JcHVQ48P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangxuanWu/Python/blob/master/NewProjectInFall/ML-7/ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EioozTCEmy3Z",
        "outputId": "4c268732-aeab-4ae6-ad1a-5e52834176e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXr9xcpPm0Hf",
        "outputId": "5a8a78eb-390d-4b52-c4ba-954620e2a3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1bot_feaure_pics\n",
            "'1_importance_list_for_bot_attack (1).csv'\n",
            " 1_importance_list_for_bot_attack.csv\n",
            " all_data.csv\n",
            " attacks\n",
            " Bot\n",
            " bot_feaure_pics\n",
            "'Colab Notebooks'\n",
            " CSVs\n",
            " feaure_pics\n",
            " importance_list_all_data.csv\n",
            " importance_list_for_attack_files.csv\n",
            " importance_list_for_bot_attack_files.csv\n",
            " results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUE1V-p0m0J2",
        "outputId": "72da73ae-4f30-40bb-b5aa-71f9c8f68356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "##5.1 “all_data。程序的操作需要csv文件。\n",
        "# #”all_data。csv文件必须位于与程序相同的目录中。\n",
        "##这个程序的目的是将机器学习算法应用到数据集，并观察算法的性能。使用的算法有:Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP, Nearest neighbour\n",
        "##作为程序显示输出的数据包括:文件名、机器学习算法名称、准确率、精度、召回率、f1得分、时间\n",
        "##该程序将创建一个CSV文件，该文件将打印结果和包含结果的文件夹\n",
        "\n",
        "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
        "##  http://scikit-learn.org\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#%matplotlib inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "result=\"./results/results_1.csv\" #a CSV file is named in which the results are saved.\n",
        "csv_files=os.listdir(\"Bot\")# 获取攻击文件夹中的文件名称并分配给一个列表(csv_files)。\n",
        "path=\"./attacks/Bot.csv\"\n",
        "repetition=10\n",
        "\n",
        "\n",
        "def folder(f_name): #this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
        "    try:\n",
        "        if not os.path.exists(f_name):\n",
        "            os.makedirs(f_name)\n",
        "    except OSError:\n",
        "        print (\"The folder could not be created!\")\n",
        "\n",
        "\n",
        "folder_name=\"./results/bot_result_graph_1/\"\n",
        "folder(folder_name)\n",
        "\n",
        "\n",
        "#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
        "#ml_list={\n",
        "#\"Naive Bayes\":GaussianNB()\n",
        "#\"QDA\":QDA()\n",
        "#\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "#\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
        "#\"AdaBoost\":AdaBoostClassifier(),\n",
        "#\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
        "#\"Nearest Neighbors\":KNeighborsClassifier(3)}\n",
        "\n",
        "\n",
        "\n",
        "# the features to be used for each attack type is defined in a dictionary(features).\n",
        "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
        "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Min\",\"Label\"]}\n",
        "\n",
        "seconds=time.time()#time stamp for all processing time\n",
        "\n",
        "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
        "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
        "    \n",
        "    \n",
        "    feature_list=list(features[j[0:-4]])\n",
        "    df=pd.read_csv(path\n",
        "                   ,usecols=feature_list)#read an attack file.\n",
        "    print(j[0:-4])\n",
        "    df=df.fillna(0)\n",
        "    attack_or_not=[]\n",
        "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
        "        \n",
        "        if i ==\"BENIGN\":\n",
        "            attack_or_not.append(1)\n",
        "        else:\n",
        "            attack_or_not.append(0)           \n",
        "    df[\"Label\"]=attack_or_not\n",
        "\n",
        "    for col in feature_list:\n",
        "      m = df.loc[df[col] != np.inf, col].max()\n",
        "      df[col].replace(np.inf, m, inplace = True)\n",
        "\n",
        "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
        "    del df[\"Label\"]\n",
        "    feature_list.remove('Label')\n",
        "    X = df[feature_list]\n",
        "\n",
        "    \n",
        "    \n",
        "    for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
        "          second=time.time()#time stamp for processing time\n",
        "\n",
        "            # cross-validation\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
        "\n",
        "\n",
        "            #machine learning algorithm is applied in this section\n",
        "          clf = DecisionTreeClassifier(max_depth=5,criterion=\"entropy\")                                                                          \n",
        "          clf.fit(X_train, y_train)\n",
        "          predict =clf.predict(X_test)\n",
        "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
        "                  \n",
        "          f_1=f1_score(y_test, predict, average='macro')\n",
        "          pr=precision_score(y_test, predict, average='macro')\n",
        "          rc=recall_score(y_test, predict, average='macro')\n",
        "\n",
        "            \n",
        "            \n",
        "            \n",
        "          precision=[]\n",
        "          recall=[]\n",
        "          f1=[]\n",
        "          accuracy=[]\n",
        "          t_time=[]  \n",
        "          precision.append(float(pr))\n",
        "          recall.append(float(rc))\n",
        "          f1.append(float(f_1))\n",
        "          accuracy.append(clf.score(X_test, y_test))\n",
        "          t_time.append(float((time.time()-second)) )\n",
        "\n",
        "\n",
        "            \n",
        "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],\"ID3\" ,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
        "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
        "\n",
        "    with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
        "            wrt = csv.writer(f)\n",
        "            for i in range(0,len(t_time)):\n",
        "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
        "    a=[]\n",
        "    a.append(f1)\n",
        "\n",
        "\n",
        "     # 将为机器学习算法的结果创建方框图形并保存在feaure_graph文件夹中。\n",
        "    #ml=[\"Naive Bayes\"]\n",
        "    #temp=0\n",
        "    #fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 6), sharey=True)\n",
        "    #axes.boxplot(a[temp] )\n",
        "    #axes.set_title(str(j[0:-4])+\" - \"+str(ml[temp]),fontsize=7)\n",
        "    #axes.set_ylabel((\"F measure\"))\n",
        "    #plt.savefig(folder_name+j[0:-4]+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
        "    #plt.show()\n",
        "    #print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "    \n",
        "print(\"mission accomplished!\")\n",
        "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
            "Bot\n",
            "Bot               ID3                0.94            0.92            0.94            0.93            0.0113         \n",
            "mission accomplished!\n",
            "Total operation time: =  0.1522383689880371 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}