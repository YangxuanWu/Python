{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New-EachAttack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7Bea7JIRRl+daqD88CZB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangxuanWu/Python/blob/master/NewProjectInFall/ML-7-1/New_EachAttack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Q0yi9ONER3",
        "outputId": "341d13a9-934f-4b7c-dca9-aced61087c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1TeTyogNFHR",
        "outputId": "0ae37127-c53b-4024-c5d3-8af2f18b0800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1bot_feaure_pics\n",
            "'1_importance_list_for_bot_attack (1).csv'\n",
            " 1_importance_list_for_bot_attack.csv\n",
            " all_data.csv\n",
            " attacks\n",
            " Bot\n",
            " bot_feaure_pics\n",
            "'Colab Notebooks'\n",
            " CSVs\n",
            " feaure_pics\n",
            " importance_list_all_data.csv\n",
            " importance_list_for_attack_files.csv\n",
            " importance_list_for_bot_attack_files.csv\n",
            " results\n",
            "'Yangxuan Wu.zip'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKsDHmmANG4Z",
        "outputId": "dffc4be9-616a-4d92-aa2c-1b85477abc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#%matplotlib inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "result=\"./results/results_1.csv\" #a CSV file is named in which the results are saved.\n",
        "csv_files=os.listdir(\"attacks\")# 获取攻击文件夹中的文件名称并分配给一个列表(csv_files)。\n",
        "path=\".\\\\attacks\\\\\"\n",
        "repetition=10\n",
        "\n",
        "\n",
        "def folder(f_name): #this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
        "    try:\n",
        "        if not os.path.exists(f_name):\n",
        "            os.makedirs(f_name)\n",
        "    except OSError:\n",
        "        print (\"The folder could not be created!\")\n",
        "\n",
        "folder_name=\"./results/\"\n",
        "folder(folder_name)\n",
        "folder_name=\"./results/result_graph_1/\"\n",
        "folder(folder_name)\n",
        "\n",
        "\n",
        "#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
        "ml_list={\n",
        "#\"Naive Bayes\":GaussianNB(),\n",
        "#\"QDA\":QDA(),\n",
        "#\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "#\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
        "#\"AdaBoost\":AdaBoostClassifier(),\n",
        "#\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
        "\n",
        "\"SGDClassifier\":Pipeline([(\"scaler\", StandardScaler()),(\"SGDClassifier\", SGDClassifier(random_state=42))]),\n",
        "\"rbf_kernel_svm_clf\":Pipeline([(\"scaler\", StandardScaler()),(\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))]),\n",
        "\"polynomial_svm_clf\":Pipeline([(\"poly_features\", PolynomialFeatures(degree=3)),(\"scaler\", StandardScaler()),(\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))]),\n",
        "\"svm_clf\":Pipeline([(\"scaler\", StandardScaler()),(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))]),\n",
        "\"Nearest Neighbors\":KNeighborsClassifier(3),\n",
        "\"ppn\":Perceptron()\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# the features to be used for each attack type is defined in a dictionary(features).\n",
        "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
        "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Min\",\"Label\"],\n",
        "\"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
        "\"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
        "\"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
        "\"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Bwd Packet Length Mean\",\"Total Length of Bwd Packets\",\"Label\"],\n",
        "\"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
        "\"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Label\"],\n",
        "\"Heartbleed\":[\"Total Backward Packets\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Bwd Packet Length Max\",\"Label\"],\n",
        "\"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
        "\"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
        "\"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Total Length of Fwd Packets\",\"Label\"],\n",
        "\"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Max\",\"Label\"]}\n",
        "\n",
        "seconds=time.time()#time stamp for all processing time\n",
        "\n",
        "\n",
        "\n",
        "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#a CSV file is created to save the results obtained.\n",
        "    wrt = csv.writer(f)\n",
        "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
        "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
        "    a=[]\n",
        "\n",
        "    feature_list=list(features[j[0:-4]])\n",
        "    df=pd.read_csv(path+j, usecols=feature_list)#read an attack file.\n",
        "\n",
        "    df=df.fillna(0)\n",
        "    attack_or_not=[]\n",
        "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
        "        \n",
        "        if i ==\"BENIGN\":\n",
        "            attack_or_not.append(1)\n",
        "        else:\n",
        "            attack_or_not.append(0)           \n",
        "    df[\"Label\"]=attack_or_not\n",
        "\n",
        "    for col in feature_list:\n",
        "      m = df.loc[df[col] != np.inf, col].max()\n",
        "      df[col].replace(np.inf, m, inplace = True)\n",
        "\n",
        "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
        "    del df[\"Label\"]\n",
        "    feature_list.remove('Label')\n",
        "    X = df[feature_list]\n",
        "\n",
        "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
        "        precision=[]\n",
        "        recall=[]\n",
        "        f1=[]\n",
        "        accuracy=[]\n",
        "        t_time=[]\n",
        "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
        "            second=time.time()#time stamp for processing time\n",
        "\n",
        "            # cross-validation\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
        "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
        "\n",
        "            #machine learing algorithm is applied in this section\n",
        "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
        "            clf.fit(X_train, y_train)\n",
        "            predict =clf.predict(X_test)\n",
        "        \n",
        "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
        "            f_1=f1_score(y_test, predict, average='macro')\n",
        "            pr=precision_score(y_test, predict, average='macro')\n",
        "            rc=recall_score(y_test, predict, average='macro')\n",
        "            precision.append(float(pr))\n",
        "            recall.append(float(rc))\n",
        "            f1.append(float(f_1))\n",
        "            accuracy.append(clf.score(X_test, y_test))\n",
        "            t_time.append(float((time.time()-second))\n",
        "            )\n",
        "\n",
        "\n",
        "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)),str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
        "\n",
        "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
        "            wrt = csv.writer(f)\n",
        "            for i in range(0,len(t_time)):\n",
        "                wrt.writerow([j[0:-4],accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
        "        a.append(f1)\n",
        "\n",
        "print(\"mission accomplished!\")\n",
        "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")\n",
        "\n",
        "\n",
        "#k_range = range(1,15)\n",
        "#cv_scores = []\n",
        "#for n in k_range:\n",
        "    #knn = KNeighborsClassifier(n)\n",
        "    #scores = cross_val_score(SGDClassifier(random_state=42), X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "    #cv_scores.append(scores.mean())\n",
        "#plt.plot(k_range,cv_scores)\n",
        "#plt.xlabel('K')\n",
        "#plt.ylabel('Accuracy')\t\t#通过图像选择最好的参数\n",
        "#plt.show()\n",
        "#best_knn = KNeighborsClassifier(n_neighbors=3)\t# 选择最优的K=3传入模型\n",
        "#best_knn.fit(X_train,y_train)\t\t\t#训练模型\n",
        "#print(best_knn.score(X_train,y_train))\t#看看评分\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
            "Bot               SGDClassifier      0.71            0.35            0.5             0.41            0.0234         \n",
            "Bot               rbf_kernel_svm_clf  0.71            0.35            0.5             0.41            0.9076         \n",
            "Bot               polynomial_svm_clf  0.7             0.66            0.69            0.67            0.1084         \n",
            "Bot               svm_clf            0.71            0.35            0.5             0.41            0.0245         \n",
            "Bot               Nearest Neighbors  0.96            0.94            0.95            0.95            0.0861         \n",
            "Bot               ppn                0.71            0.85            0.5             0.42            0.0113         \n",
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
            "DDoS              SGDClassifier      0.87            0.89            0.8             0.83            0.2791         \n",
            "DDoS              rbf_kernel_svm_clf  0.9             0.88            0.89            0.89            303.2388       \n",
            "DDoS              polynomial_svm_clf  0.92            0.9             0.91            0.91            33.9458        \n",
            "DDoS              svm_clf            0.87            0.89            0.8             0.83            2.2472         \n",
            "DDoS              Nearest Neighbors  0.93            0.91            0.92            0.91            3.0256         \n",
            "DDoS              ppn                0.7             0.53            0.5             0.41            0.3195         \n",
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
            "DoS GoldenEye     SGDClassifier      0.95            0.94            0.93            0.93            0.0766         \n",
            "DoS GoldenEye     rbf_kernel_svm_clf  0.92            0.89            0.92            0.9             16.4521        \n",
            "DoS GoldenEye     polynomial_svm_clf  0.99            0.98            0.98            0.98            2.5425         \n",
            "DoS GoldenEye     svm_clf            0.94            0.94            0.92            0.93            0.1181         \n",
            "DoS GoldenEye     Nearest Neighbors  0.98            0.97            0.98            0.97            0.4485         \n",
            "DoS GoldenEye     ppn                0.29            0.65            0.5             0.23            0.0465         \n",
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
            "DoS Hulk          SGDClassifier      0.89            0.89            0.82            0.85            1.2911         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4xq3rwuZ6T8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}