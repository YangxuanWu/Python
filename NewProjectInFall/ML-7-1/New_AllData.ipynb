{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New-AllData.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOe5ZuYMqs7mBrDBccf+7ZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangxuanWu/Python/blob/master/NewProjectInFall/ML-7-1/New_AllData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_0cq7f9Z9Xo",
        "outputId": "dfb7aaf2-bc2f-4c65-a8b4-95beb45cad91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvelArOuZ-Ji",
        "outputId": "642de8a2-538a-45b2-b63e-2e5004ade977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  results\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AWjHbimZ_Q-",
        "outputId": "41ff01e3-5c3d-4dc5-9b5b-bb70c336f3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#%matplotlib inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "result=\"./results/results_2.csv\" #a CSV file is named in which the results are saved.\n",
        "csv_files=[\"all_data.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
        "path=\"\"\n",
        "repetition=10\n",
        "\n",
        "\n",
        "def folder(f_name): #this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
        "    try:\n",
        "        if not os.path.exists(f_name):\n",
        "            os.makedirs(f_name)\n",
        "    except OSError:\n",
        "        print (\"The folder could not be created!\")\n",
        "\n",
        "folder_name=\"./results/\"\n",
        "folder(folder_name)\n",
        "folder_name=\"./results/result_graph_2/\"\n",
        "folder(folder_name)\n",
        "\n",
        "\n",
        "#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
        "ml_list={\n",
        "#\"Naive Bayes\":GaussianNB(),\n",
        "#\"QDA\":QDA(),\n",
        "#\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "#\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
        "#\"AdaBoost\":AdaBoostClassifier(),\n",
        "#\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
        "#\"Nearest Neighbors\":KNeighborsClassifier(3)\n",
        "#\"SGDClassifier\":Pipeline([(\"scaler\", StandardScaler()),(\"SGDClassifier\", SGDClassifier(random_state=42))])\n",
        "#\"SGDClassifier\":SGDClassifier(random_state=42),\n",
        "\"polynomial_svm_clf\":Pipeline([(\"poly_features\", PolynomialFeatures(degree=3)),(\"scaler\", StandardScaler()),(\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))]),\n",
        "\"svm_clf\":Pipeline([(\"scaler\", StandardScaler()),(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))]),\n",
        "\"log_reg\":SGDClassifier(loss = 'log'),\n",
        "\"ppn\":SGDClassifier(loss = 'perceptron')\n",
        "#\"lasso_reg\":Lasso(alpha=0.1)\n",
        "}\n",
        "\n",
        "features={\"all_data\":[\"Bwd Packet Length Max\",\"Bwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Flow Bytes/s\",\n",
        "\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Flow IAT Min\",\"Flow IAT Std\",\"Fwd IAT Total\",\"Fwd Packet Length Max\",\n",
        "\"Fwd Packet Length Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Total Backward Packets\",\"Total Fwd Packets\",\n",
        "\"Total Length of Bwd Packets\",\"Total Length of Fwd Packets\",\"Label\"]}\n",
        "\n",
        "seconds=time.time()#time stamp for all processing time\n",
        "\n",
        "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#a CSV file is created to save the results obtained.\n",
        "    wrt = csv.writer(f)\n",
        "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
        "\n",
        "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
        "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header   \n",
        "    feature_list=list(features[j[0:-4]])\n",
        "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
        "    df=df.fillna(0)\n",
        "    attack_or_not=[]\n",
        "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
        "        \n",
        "        if i ==\"BENIGN\":\n",
        "            attack_or_not.append(1)\n",
        "        else:\n",
        "            attack_or_not.append(0)           \n",
        "    df[\"Label\"]=attack_or_not\n",
        "\n",
        "    for col in feature_list:\n",
        "      m = df.loc[df[col] != np.inf, col].max()\n",
        "      df[col].replace(np.inf, m, inplace = True)\n",
        "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
        "    del df[\"Label\"]\n",
        "    feature_list.remove('Label')\n",
        "    X = df[feature_list]\n",
        "   \n",
        "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
        "        precision=[]\n",
        "        recall=[]\n",
        "        f1=[]\n",
        "        accuracy=[]\n",
        "        t_time=[]\n",
        "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
        "            second=time.time()#time stamp for processing time\n",
        "\n",
        "            # cross-validation\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
        "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
        "\n",
        "            #machine learning algorithm is applied in this section\n",
        "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
        "            clf.fit(X_train, y_train)\n",
        "            predict =clf.predict(X_test)\n",
        "        \n",
        "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
        "            \n",
        "            f_1=f1_score(y_test, predict, average='macro')\n",
        "            pr=precision_score(y_test, predict, average='macro')\n",
        "            rc=recall_score(y_test, predict, average='macro')\n",
        "                      \n",
        "            precision.append(float(pr))\n",
        "            recall.append(float(rc))\n",
        "            f1.append(float(f_1))\n",
        "            accuracy.append(clf.score(X_test, y_test))\n",
        "            t_time.append(float((time.time()-second)))\n",
        "            \n",
        "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
        "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
        "\n",
        "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
        "            wrt = csv.writer(f)\n",
        "            for i in range(0,len(t_time)):\n",
        "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
        "   \n",
        "print(\"mission accomplished!\")\n",
        "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}