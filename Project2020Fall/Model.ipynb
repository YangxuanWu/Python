{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPV5QJVTvpqdNH4D2z8aF2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangxuanWu/Python/blob/master/Project2020Fall/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vo1PC5VyVgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "import tfsnippet as spt\n",
        "from tensorflow.python.ops.linalg.linear_operator_identity import LinearOperatorIdentity\n",
        "from tensorflow_probability.python.distributions import LinearGaussianStateSpaceModel, MultivariateNormalDiag\n",
        "from tfsnippet.distributions import Normal\n",
        "from tfsnippet.utils import VarScopeObject, reopen_variable_scope\n",
        "from tfsnippet.variational import VariationalInference\n",
        "\n",
        "from omni_anomaly.recurrent_distribution import RecurrentDistribution\n",
        "from omni_anomaly.vae import Lambda, VAE\n",
        "from omni_anomaly.wrapper import TfpDistribution, softplus_std, rnn, wrap_params_net\n",
        "\n",
        "\n",
        "class OmniAnomaly(VarScopeObject):\n",
        "    def __init__(self, config, name=None, scope=None):\n",
        "        self.config = config\n",
        "        super(OmniAnomaly, self).__init__(name=name, scope=scope)\n",
        "        with reopen_variable_scope(self.variable_scope):\n",
        "            if config.posterior_flow_type == 'nf':\n",
        "                self._posterior_flow = spt.layers.planar_normalizing_flows(\n",
        "                    config.nf_layers, name='posterior_flow')\n",
        "            else:\n",
        "                self._posterior_flow = None\n",
        "            self._window_length = config.window_length\n",
        "            self._x_dims = config.x_dim\n",
        "            self._z_dims = config.z_dim\n",
        "            self._vae = VAE(\n",
        "                p_z=TfpDistribution(\n",
        "                    LinearGaussianStateSpaceModel(\n",
        "                        num_timesteps=config.window_length,\n",
        "                        transition_matrix=LinearOperatorIdentity(config.z_dim),\n",
        "                        transition_noise=MultivariateNormalDiag(\n",
        "                            scale_diag=tf.ones([config.z_dim])),\n",
        "                        observation_matrix=LinearOperatorIdentity(config.z_dim),\n",
        "                        observation_noise=MultivariateNormalDiag(\n",
        "                            scale_diag=tf.ones([config.z_dim])),\n",
        "                        initial_state_prior=MultivariateNormalDiag(\n",
        "                            scale_diag=tf.ones([config.z_dim]))\n",
        "                    )\n",
        "                ) if config.use_connected_z_p else Normal(mean=tf.zeros([config.z_dim]), std=tf.ones([config.z_dim])),\n",
        "                p_x_given_z=Normal,\n",
        "                q_z_given_x=partial(RecurrentDistribution,\n",
        "                                    mean_q_mlp=partial(tf.layers.dense, units=config.z_dim, name='z_mean', reuse=tf.AUTO_REUSE),\n",
        "                                    std_q_mlp=partial(softplus_std, units=config.z_dim, epsilon=config.std_epsilon,\n",
        "                                                      name='z_std'),\n",
        "                                    z_dim=config.z_dim, window_length=config.window_length) if config.use_connected_z_q else Normal,\n",
        "                h_for_p_x=Lambda(\n",
        "                    partial(\n",
        "                        wrap_params_net,\n",
        "                        h_for_dist=lambda x: rnn(x=x,\n",
        "                                                 window_length=config.window_length,\n",
        "                                                 rnn_num_hidden=config.rnn_num_hidden,\n",
        "                                                 hidden_dense=2,\n",
        "                                                 dense_dim=config.dense_dim,\n",
        "                                                 name='rnn_p_x'),\n",
        "                        mean_layer=partial(\n",
        "                            tf.layers.dense, units=config.x_dim, name='x_mean', reuse=tf.AUTO_REUSE\n",
        "                        ),\n",
        "                        std_layer=partial(\n",
        "                            softplus_std, units=config.x_dim, epsilon=config.std_epsilon,\n",
        "                            name='x_std'\n",
        "                        )\n",
        "                    ),\n",
        "                    name='p_x_given_z'\n",
        "                ),\n",
        "                h_for_q_z=Lambda(\n",
        "                    lambda x: {'input_q': rnn(x=x,\n",
        "                                              window_length=config.window_length,\n",
        "                                              rnn_num_hidden=config.rnn_num_hidden,\n",
        "                                              hidden_dense=2,\n",
        "                                              dense_dim=config.dense_dim,\n",
        "                                              name=\"rnn_q_z\")},\n",
        "                    name='q_z_given_x'\n",
        "                ) if config.use_connected_z_q else Lambda(\n",
        "                    partial(\n",
        "                        wrap_params_net,\n",
        "                        h_for_dist=lambda x: rnn(x=x,\n",
        "                                                 window_length=config.window_length,\n",
        "                                                 rnn_num_hidden=config.rnn_num_hidden,\n",
        "                                                 hidden_dense=2,\n",
        "                                                 dense_dim=config.dense_dim,\n",
        "                                                 name=\"rnn_q_z\"),\n",
        "                        mean_layer=partial(\n",
        "                            tf.layers.dense, units=config.z_dim, name='z_mean', reuse=tf.AUTO_REUSE\n",
        "                        ),\n",
        "                        std_layer=partial(\n",
        "                            softplus_std, units=config.z_dim, epsilon=config.std_epsilon,\n",
        "                            name='z_std'\n",
        "                        )\n",
        "                    ),\n",
        "                    name='q_z_given_x'\n",
        "                )\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def x_dims(self):\n",
        "        \"\"\"Get the number of `x` dimensions.\"\"\"\n",
        "        return self._x_dims\n",
        "\n",
        "    @property\n",
        "    def z_dims(self):\n",
        "        \"\"\"Get the number of `z` dimensions.\"\"\"\n",
        "        return self._z_dims\n",
        "\n",
        "    @property\n",
        "    def vae(self):\n",
        "        \"\"\"\n",
        "        Get the VAE object of this :class:`OmniAnomaly` model.\n",
        "\n",
        "        Returns:\n",
        "            VAE: The VAE object of this model.\n",
        "        \"\"\"\n",
        "        return self._vae\n",
        "\n",
        "    @property\n",
        "    def window_length(self):\n",
        "        return self._window_length\n",
        "\n",
        "    def get_training_loss(self, x, n_z=None):\n",
        "        \"\"\"\n",
        "        Get the training loss for `x`.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): 2-D `float32` :class:`tf.Tensor`, the windows of\n",
        "                KPI observations in a mini-batch.\n",
        "            n_z (int or None): Number of `z` samples to take for each `x`.\n",
        "                (default :obj:`None`, one sample without explicit sampling\n",
        "                dimension)\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: 0-d tensor, the training loss, which can be optimized\n",
        "                by gradient descent algorithms.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('training_loss'):\n",
        "            chain = self.vae.chain(x, n_z=n_z, posterior_flow=self._posterior_flow)\n",
        "            x_log_prob = chain.model['x'].log_prob(group_ndims=0)\n",
        "            log_joint = tf.reduce_sum(x_log_prob, -1)\n",
        "            chain.vi.training.sgvb()\n",
        "            vi = VariationalInference(\n",
        "                log_joint=log_joint,\n",
        "                latent_log_probs=chain.vi.latent_log_probs,\n",
        "                axis=chain.vi.axis\n",
        "            )\n",
        "            loss = tf.reduce_mean(vi.training.sgvb())\n",
        "            return loss\n",
        "\n",
        "    def get_score(self, x, n_z=None,\n",
        "                  last_point_only=True):\n",
        "        \"\"\"\n",
        "        Get the reconstruction probability for `x`.\n",
        "\n",
        "        The larger `reconstruction probability`, the less likely a point\n",
        "        is anomaly.  You may take the negative of the score, if you want\n",
        "        something to directly indicate the severity of anomaly.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): 2-D `float32` :class:`tf.Tensor`, the windows of\n",
        "                KPI observations in a mini-batch.\n",
        "            n_z (int or None): Number of `z` samples to take for each `x`.\n",
        "                (default :obj:`None`, one sample without explicit sampling\n",
        "                dimension)\n",
        "            last_point_only (bool): Whether to obtain the reconstruction\n",
        "                probability of only the last point in each window?\n",
        "                (default :obj:`True`)\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The reconstruction probability, with the shape\n",
        "                ``(len(x) - self.x_dims + 1,)`` if `last_point_only` is\n",
        "                :obj:`True`, or ``(len(x) - self.x_dims + 1, self.x_dims)``\n",
        "                if `last_point_only` is :obj:`False`.  This is because the\n",
        "                first ``self.x_dims - 1`` points are not the last point of\n",
        "                any window.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('get_score'):\n",
        "            x_r = x\n",
        "\n",
        "            # get the reconstruction probability\n",
        "            print('-' * 30, 'testing', '-' * 30)\n",
        "            q_net = self.vae.variational(x=x_r, n_z=n_z, posterior_flow=self._posterior_flow)  # notice: x=x_r\n",
        "            p_net = self.vae.model(z=q_net['z'], x=x, n_z=n_z)  # notice: x=x\n",
        "            z_samples = q_net['z'].tensor\n",
        "            z_mean = tf.reduce_mean(z_samples, axis=0) if n_z is not None else z_samples\n",
        "            z_std = tf.sqrt(tf.reduce_sum(tf.square(z_samples - z_mean), axis=0) / (n_z - 1)) \\\n",
        "                if n_z is not None and n_z > 1 else tf.zeros_like(z_mean)\n",
        "            z = tf.concat((z_mean, z_std), axis=-1)\n",
        "\n",
        "            r_prob = p_net['x'].log_prob(group_ndims=int(not self.config.get_score_on_dim))\n",
        "\n",
        "            if last_point_only:\n",
        "                r_prob = r_prob[:, -1]\n",
        "            return r_prob, z\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}